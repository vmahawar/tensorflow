{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOAitCQ1pXTk6FWA2QJB0mx",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/vmahawar/tensorflow/blob/main/01_neural_network_regression_with_tensorflow.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Introduction to regression with Neural Networks in Tensorflow\n",
        "\n",
        "There are many definitions for a regresssion problem but in our case, we're going to simplify it: predicting a numerical variable based on some other combination of variable, even shorter... predicting a number"
      ],
      "metadata": {
        "id": "_5ZymjswP5bN"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HkaGlmmcPeEz",
        "outputId": "b34a02a0-da1c-4607-c0c2-b2ae3c5f4e97"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.17.0\n"
          ]
        }
      ],
      "source": [
        "# Import TensorFlow\n",
        "\n",
        "import tensorflow as tf\n",
        "print(tf.__version__)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create some data to view and fit\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Create features\n",
        "X = np.array([-7.0, -4.0, -1.0, 2.0, 5.0, 8.0, 11.0, 14.0])\n",
        "\n",
        "# Create labels\n",
        "y = np.array([3.0, 6.0, 9.0, 12.0, 15.0, 18.0, 21.0, 24.0])\n",
        "\n",
        "# Visualize it\n",
        "plt.scatter(X, y)\n",
        "plt.xlabel(\"X\")\n",
        "plt.ylabel(\"y\")\n",
        "plt.title(\"Some Data\")\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 472
        },
        "id": "obr8Rlu-QX0G",
        "outputId": "02984416-7f6e-4a72-b56a-b1c877021140"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAjoAAAHHCAYAAAC2rPKaAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAAApFElEQVR4nO3df3DU9Z3H8ddmIVnUsFwwyW4whAACxgDKj0R6+IMCJqipYNXCiYJa7y6DHILoSSuEtNYInaKjw4HtXauW+qN6SA9tUxEExiEQDwoaUy2kUUA2QQhsAkwCZL/3B5cdliSwCUm+ux+ej5md6X72m80bdzJ59vsrDsuyLAEAABgoxu4BAAAAOguhAwAAjEXoAAAAYxE6AADAWIQOAAAwFqEDAACMRegAAABjEToAAMBYhA4AADAWoQMAAIxF6AAI8dlnn+nuu+9WWlqaXC6X+vTpo4kTJ+qll16ye7R2cTgcwUe3bt2UkJCgkSNHas6cOSovL2/3+544cUKLFy/Wxo0bO25YAB3Owd+6AtBky5YtGjdunPr27asZM2bI4/Fo37592rp1qyoqKrRnzx67R2wzh8OhiRMn6oEHHpBlWfL7/dq1a5fefvttHT9+XEuWLNG8efPa/L6HDh1SYmKiCgoKtHjx4o4fHECH6Gb3AAAix89+9jO53W598skn6tWrV8hrBw8etGeoDjBo0CBNnz49ZO25555TXl6eHn/8cQ0ZMkS33XabTdMB6EwcugIQVFFRoWuvvbZZ5EhSUlJSyPPTp0/rpz/9qQYMGKC4uDj169dPP/rRj9TQ0BCyXb9+/XTHHXdo48aNGjVqlHr06KGhQ4cGD/msXr1aQ4cOlcvl0siRI/WXv/yl2ff+4osvdPfddyshIUEul0ujRo3S//zP/1zUv7V3795688031a1bN/3sZz8Lrp88eVKLFi3SyJEj5Xa7dfnll+vGG2/URx99FNzmq6++UmJioiSpsLAweGisac/Op59+qpkzZ6p///5yuVzyeDx66KGHdPjw4YuaGUDbEToAgtLS0rR9+3aVlZVdcNsf/vCHWrRokUaMGKHnn39eN998s4qKijR16tRm2+7Zs0f/9E//pLy8PBUVFenIkSPKy8vT7373O82dO1fTp09XYWGhKioqdO+99yoQCAS/9vPPP9cNN9ygv/71r3rqqaf0i1/8QpdffrkmT56sd99996L+vX379tXNN9+srVu3qra2VpJUW1ur//zP/9Qtt9yiJUuWaPHixfr222+Vk5OjnTt3SpISExO1YsUKSdKUKVP029/+Vr/97W911113SZLWrVunv//973rwwQf10ksvaerUqXrzzTd12223ibMFgC5mAcD/++CDDyyn02k5nU5rzJgx1pNPPmn9+c9/tk6ePBmy3c6dOy1J1g9/+MOQ9fnz51uSrA0bNgTX0tLSLEnWli1bgmt//vOfLUlWjx49rK+//jq4/vLLL1uSrI8++ii4Nn78eGvo0KFWfX19cC0QCFjf+c53rKuvvvqC/yZJ1qxZs1p9fc6cOZYka9euXZZlWdbp06ethoaGkG2OHDliJScnWw899FBw7dtvv7UkWQUFBc3e88SJE83W3njjDUuStXnz5gvODKDjsEcHQNDEiRNVUlKi733ve9q1a5eWLl2qnJwc9enTJ+RQ0R//+EdJanYS7+OPPy5Jev/990PWMzIyNGbMmODz7OxsSdJ3v/td9e3bt9n63//+d0lSTU2NNmzYoHvvvVd1dXU6dOiQDh06pMOHDysnJ0e7d+/WN998c1H/5iuuuEKSVFdXJ0lyOp2KjY2VJAUCAdXU1Oj06dMaNWqUduzYEdZ79ujRI/i/6+vrdejQId1www2SFPZ7AOgYhA6AEKNHj9bq1at15MgRlZaWasGCBaqrq9Pdd98dvBz766+/VkxMjAYOHBjytR6PR7169dLXX38dsn52zEiS2+2WJKWmpra4fuTIEUlnDnlZlqWFCxcqMTEx5FFQUCDp4k+SPnbsmCQpPj4+uPbqq69q2LBhcrlc6t27txITE/X+++/L7/eH9Z41NTWaM2eOkpOT1aNHDyUmJio9PV2Swn4PAB2Dq64AtCg2NlajR4/W6NGjNWjQID344IN6++23g4Ehnbl0OxxOp7NN69b/n8fSdK7O/PnzlZOT0+K258ZWW5WVlcnpdAZDZNWqVZo5c6YmT56sJ554QklJSXI6nSoqKlJFRUVY73nvvfdqy5YteuKJJ3TdddfpiiuuUCAQUG5ubsj5RwA6H6ED4IJGjRolSfL5fJLOnLQcCAS0e/duXXPNNcHtqqurdfToUaWlpXXI9+3fv78kqXv37powYUKHvOfZ9u7dq02bNmnMmDHBPTrvvPOO+vfvr9WrV4eE3NmBJ7UeeUeOHNH69etVWFioRYsWBdd3797d4fMDuDAOXQEI+uijj1q8KqjpnJzBgwdLUvCeMy+88ELIdsuWLZMk3X777R0yT1JSkm655Ra9/PLLwcg627ffftvu966pqdG0adPU2NioH//4x8H1pr1MZ/932LZtm0pKSkK+/rLLLpMkHT16NGS9pa+Xmv+3AtA12KMDIGj27Nk6ceKEpkyZoiFDhujkyZPasmWL3nrrLfXr108PPvigJGn48OGaMWOGfvnLX+ro0aO6+eabVVpaqldffVWTJ0/WuHHjOmym5cuXa+zYsRo6dKgeeeQR9e/fX9XV1SopKdH+/fu1a9euC77H3/72N61atUqWZam2tjZ4Z+Rjx45p2bJlys3NDW57xx13aPXq1ZoyZYpuv/12VVZWauXKlcrIyAiezyOdOeE4IyNDb731lgYNGqSEhARlZmYqMzNTN910k5YuXapTp06pT58++uCDD1RZWdlh/00AtIGdl3wBiCx/+tOfrIceesgaMmSIdcUVV1ixsbHWwIEDrdmzZ1vV1dUh2546dcoqLCy00tPTre7du1upqanWggULQi4Dt6wzl5fffvvtzb6XWrjsu7Ky0pJk/fznPw9Zr6iosB544AHL4/FY3bt3t/r06WPdcccd1jvvvHPBf5Ok4CMmJsbq1auXdf3111tz5syxPv/882bbBwIB69lnn7XS0tKsuLg46/rrr7fee+89a8aMGVZaWlrItlu2bLFGjhxpxcbGhlxqvn//fmvKlClWr169LLfbbd1zzz3WgQMHWr0cHUDn4W9dAQAAY3GODgAAMBahAwAAjEXoAAAAYxE6AADAWLaGTlFRkUaPHq34+HglJSVp8uTJ+vLLL0O2ueWWW+RwOEIe//qv/2rTxAAAIJrYGjqbNm3SrFmztHXrVq1bt06nTp3SrbfequPHj4ds98gjj8jn8wUfS5cutWliAAAQTWy9YWBxcXHI81deeUVJSUnavn27brrppuD6ZZddJo/H067vEQgEdODAAcXHx4f9d3kAAIC9LMtSXV2dUlJSFBPT/v0yEXVn5Ka/6puQkBCy/rvf/U6rVq2Sx+NRXl6eFi5cGLz9+rkaGhrU0NAQfP7NN98oIyOj84YGAACdZt++fbrqqqva/fURc8PAQCCg733vezp69Kg+/vjj4Povf/lLpaWlKSUlRZ9++qn+/d//XVlZWVq9enWL77N48WIVFhY2W9+3b5969uzZafMDAICOU1tbq9TUVB09elRut7vd7xMxoZOfn68//elP+vjjj89bbhs2bND48eO1Z88eDRgwoNnr5+7RafoP5ff7CR0AAKJEbW2t3G73Rf/+johDV48++qjee+89bd68+YK7p7KzsyWp1dCJi4tTXFxcp8wJAACii62hY1mWZs+erXfffVcbN25Uenr6Bb9m586dkiSv19vJ0wEAgGhna+jMmjVLr7/+uv7whz8oPj5eVVVVkiS3260ePXqooqJCr7/+um677Tb17t1bn376qebOnaubbrpJw4YNs3N0AAAQBWw9R6e1y71/85vfaObMmdq3b5+mT5+usrIyHT9+XKmpqZoyZYqefvrpsI/XddQxPgAA0HWMOEfnQo2VmpqqTZs2ddE0AADANPytKwAAYCxCBwAAGIvQAQAAxiJ0AACAsSLihoEAACC6NAYslVbW6GBdvZLiXcpKT5AzJvL+eDahAwAA2qS4zKfCteXy+euDa163SwV5GcrNjKwb+nLoCgAAhK24zKf8VTtCIkeSqvz1yl+1Q8VlPpsmaxmhAwAAwtIYsFS4tlwt3QWvaa1wbbkaAxHx98IlEToAACBMpZU1zfbknM2S5PPXq7SypuuGugBCBwAAhOVgXeuR057tugKhAwAAwpIU7+rQ7boCoQMAAMKSlZ4gr9ul1i4id+jM1VdZ6QldOdZ5EToAACAszhiHCvIyJKlZ7DQ9L8jLiKj76RA6AAAgbLmZXq2YPkIed+jhKY/bpRXTR0TcfXS4YSAAAGiT3EyvJmZ4uDMyAAAwkzPGoTEDets9xgVx6AoAABiL0AEAAMYidAAAgLEIHQAAYCxCBwAAGIvQAQAAxiJ0AACAsQgdAABgLEIHAAAYi9ABAADGInQAAICxCB0AAGAsQgcAABiL0AEAAMYidAAAgLEIHQAAYCxCBwAAGIvQAQAAxiJ0AACAsQgdAABgLEIHAAAYi9ABAADGInQAAICxCB0AAGAsQgcAABiL0AEAAMYidAAAgLEIHQAAYCxCBwAAGIvQAQAAxiJ0AACAsQgdAABgLEIHAAAYi9ABAADGInQAAICxCB0AAGCsbnYPAABANGoMWCqtrNHBunolxbuUlZ4gZ4zD7rFwDkIHAIA2Ki7zqXBtuXz++uCa1+1SQV6GcjO9Nk6Gc3HoCgCANigu8yl/1Y6QyJGkKn+98lftUHGZz6bJ0BJCBwCAMDUGLBWuLZfVwmtNa4Vry9UYaGkL2IHQAQAgTKWVNc325JzNkuTz16u0sqbrhsJ5EToAAITpYF3rkdOe7dD5CB0AAMKUFO/q0O3Q+QgdAADClJWeIK/bpdYuInfozNVXWekJXTkWzoPQAQAgTM4YhwryMiSpWew0PS/Iy+B+OhGE0AEAoA1yM71aMX2EPO7Qw1Met0srpo/gPjoRhhsGAgDQRrmZXk3M8HBn5ChA6AAA0A7OGIfGDOht9xi4AA5dAQAAYxE6AADAWIQOAAAwFqEDAACMRegAAABj2Ro6RUVFGj16tOLj45WUlKTJkyfryy+/DNmmvr5es2bNUu/evXXFFVfo+9//vqqrq22aGAAARBNbQ2fTpk2aNWuWtm7dqnXr1unUqVO69dZbdfz48eA2c+fO1dq1a/X2229r06ZNOnDggO666y4bpwYAANHCYVmWZfcQTb799lslJSVp06ZNuummm+T3+5WYmKjXX39dd999tyTpiy++0DXXXKOSkhLdcMMNF3zP2tpaud1u+f1+9ezZs7P/CQAAoAN01O/viDpHx+/3S5ISEs78MbTt27fr1KlTmjBhQnCbIUOGqG/fviopKWnxPRoaGlRbWxvyAAAAl6aICZ1AIKDHHntM//iP/6jMzExJUlVVlWJjY9WrV6+QbZOTk1VVVdXi+xQVFcntdgcfqampnT06AACIUBETOrNmzVJZWZnefPPNi3qfBQsWyO/3Bx/79u3roAkBAEC0iYi/dfXoo4/qvffe0+bNm3XVVVcF1z0ej06ePKmjR4+G7NWprq6Wx+Np8b3i4uIUFxfX2SMDAIAoYOseHcuy9Oijj+rdd9/Vhg0blJ6eHvL6yJEj1b17d61fvz649uWXX2rv3r0aM2ZMV48LAACijK17dGbNmqXXX39df/jDHxQfHx8878btdqtHjx5yu916+OGHNW/ePCUkJKhnz56aPXu2xowZE9YVVwAA4NJm6+XlDoejxfXf/OY3mjlzpqQzNwx8/PHH9cYbb6ihoUE5OTn6j//4j1YPXZ2Ly8sBAIg+HfX7O6Luo9MZCB0AAKKPkffRAQAA6EiEDgAAMBahAwAAjEXoAAAAYxE6AADAWIQOAAAwFqEDAACMRegAAABjEToAAMBYhA4AADAWoQMAAIxF6AAAAGMROgAAwFiEDgAAMBahAwAAjEXoAAAAYxE6AADAWIQOAAAwFqEDAACMRegAAABjdbN7AABAdGoMWCqtrNHBunolxbuUlZ4gZ4zD7rGAEIQOAKDNist8KlxbLp+/PrjmdbtUkJeh3EyvjZMBoTh0BQBok+Iyn/JX7QiJHEmq8tcrf9UOFZf5bJoMaI7QAQCErTFgqXBtuawWXmtaK1xbrsZAS1sAXY/QAQCErbSyptmenLNZknz+epVW1nTdUMB5EDoAgLAdrGs9ctqzHdDZCB0AQNiS4l0duh3Q2QgdAEDYstIT5HW71NpF5A6dufoqKz2hK8cCWkXoAADC5oxxqCAvQ5KaxU7T84K8DO6ng4hB6AAA2iQ306sV00fI4w49POVxu7Ri+gjuo4OIwg0DAQBtlpvp1cQMD3dGRsQjdAAA7eKMcWjMgN52jwGcF4euAACAsQgdAABgLEIHAAAYi9ABAADGInQAAICxCB0AAGAsQgcAABiL0AEAAMYidAAAgLEIHQAAYCxCBwAAGIvQAQAAxiJ0AACAsQgdAABgLEIHAAAYi9ABAADGInQAAICxCB0AAGAsQgcAABiL0AEAAMYidAAAgLEIHQAAYCxCBwAAGIvQAQAAxiJ0AACAsQgdAABgLEIHAAAYi9ABAADGInQAAICxCB0AAGAsQgcAABiL0AEAAMYidAAAgLEIHQAAYCxCBwAAGIvQAQAAxupm9wAAEI0aA5ZKK2t0sK5eSfEuZaUnyBnjsHssAOewdY/O5s2blZeXp5SUFDkcDq1Zsybk9ZkzZ8rhcIQ8cnNz7RkWAP5fcZlPY5ds0LRfbdWcN3dq2q+2auySDSou89k9GoBz2Bo6x48f1/Dhw7V8+fJWt8nNzZXP5ws+3njjjS6cEABCFZf5lL9qh3z++pD1Kn+98lftIHaACGProatJkyZp0qRJ590mLi5OHo+niyYCgNY1BiwVri2X1cJrliSHpMK15ZqY4eEwFhAhIv5k5I0bNyopKUmDBw9Wfn6+Dh8+fN7tGxoaVFtbG/IAgI5QWlnTbE/O2SxJPn+9Sitrum4oAOcV0aGTm5ur1157TevXr9eSJUu0adMmTZo0SY2Nja1+TVFRkdxud/CRmprahRMDMNnButYjpz3bAeh8EX3V1dSpU4P/e+jQoRo2bJgGDBigjRs3avz48S1+zYIFCzRv3rzg89raWmIHQIdIind16HYAOl9E79E5V//+/XXllVdqz549rW4TFxennj17hjwAoCNkpSfI63aptbNvHJK87jOXmgOIDFEVOvv379fhw4fl9XrtHgXAJcgZ41BBXoYkNYudpucFeRmciAxEEFtD59ixY9q5c6d27twpSaqsrNTOnTu1d+9eHTt2TE888YS2bt2qr776SuvXr9edd96pgQMHKicnx86xAVzCcjO9WjF9hDzu0MNTHrdLK6aPUG4m/0cMiCQOy7JaulKyS2zcuFHjxo1rtj5jxgytWLFCkydP1l/+8hcdPXpUKSkpuvXWW/XTn/5UycnJYX+P2tpaud1u+f1+DmMB6DDcGRnoXB31+9vW0OkKhA4AANGno35/R9U5OgAAAG1B6AAAAGMROgAAwFiEDgAAMBahAwAAjEXoAAAAYxE6AADAWIQOAAAwFqEDAACMRegAAABjEToAAMBYhA4AADAWoQMAAIxF6AAAAGO1OXRmzJihzZs3d8YsAAAAHarNoeP3+zVhwgRdffXVevbZZ/XNN990xlwAAAAXrc2hs2bNGn3zzTfKz8/XW2+9pX79+mnSpEl65513dOrUqc6YEQAAoF3adY5OYmKi5s2bp127dmnbtm0aOHCg7r//fqWkpGju3LnavXt3R88JAADQZhd1MrLP59O6deu0bt06OZ1O3Xbbbfrss8+UkZGh559/vqNmBAAAaJc2h86pU6f03//937rjjjuUlpamt99+W4899pgOHDigV199VR9++KF+//vf6yc/+UlnzAsAABC2bm39Aq/Xq0AgoGnTpqm0tFTXXXdds23GjRunXr16dcB4AAAA7dfm0Hn++ed1zz33yOVytbpNr169VFlZeVGDAQAAXKw2h87999/fGXMAAAB0OO6MDAAAjEXoAAAAYxE6AADAWIQOAAAwFqEDAACMRegAAABjEToAAMBYhA4AADAWoQMAAIxF6AAAAGMROgAAwFiEDgAAMBahAwAAjNXmv14OAJLUGLBUWlmjg3X1Sop3KSs9Qc4Yh91jAUAIQgdAmxWX+VS4tlw+f31wzet2qSAvQ7mZXhsnA4BQHLoC0CbFZT7lr9oREjmSVOWvV/6qHSou89k0GQA0R+gACFtjwFLh2nJZLbzWtFa4tlyNgZa2AICuR+gACFtpZU2zPTlnsyT5/PUqrazpuqEA4DwIHQBhO1jXeuS0ZzsA6GyEDoCwJcW7OnQ7AOhshA6AsGWlJ8jrdqm1i8gdOnP1VVZ6QleOBQCtInQAhM0Z41BBXoYkNYudpucFeRncTwdAxCB0ALRJbqZXK6aPkMcdenjK43ZpxfQR3EcHQEThhoEA2iw306uJGR7ujAwg4hE6ANrFGePQmAG97R4DAM6LQ1cAAMBYhA4AADAWoQMAAIxF6AAAAGMROgAAwFiEDgAAMBahAwAAjEXoAAAAYxE6AADAWIQOAAAwFqEDAACMRegAAABjEToAAMBYhA4AADAWoQMAAIxF6AAAAGMROgAAwFiEDgAAMBahAwAAjEXoAAAAYxE6AADAWLaGzubNm5WXl6eUlBQ5HA6tWbMm5HXLsrRo0SJ5vV716NFDEyZM0O7du+0ZFgAARB1bQ+f48eMaPny4li9f3uLrS5cu1YsvvqiVK1dq27Ztuvzyy5WTk6P6+vounhQAAESjbnZ+80mTJmnSpEktvmZZll544QU9/fTTuvPOOyVJr732mpKTk7VmzRpNnTq1K0cFAABRKGLP0amsrFRVVZUmTJgQXHO73crOzlZJSUmrX9fQ0KDa2tqQBwAAuDRFbOhUVVVJkpKTk0PWk5OTg6+1pKioSG63O/hITU3t1DkBAEDkitjQaa8FCxbI7/cHH/v27bN7JAAAYJOIDR2PxyNJqq6uDlmvrq4OvtaSuLg49ezZM+QBAAAuTREbOunp6fJ4PFq/fn1wrba2Vtu2bdOYMWNsnAwAAEQLW6+6OnbsmPbs2RN8XllZqZ07dyohIUF9+/bVY489pmeeeUZXX3210tPTtXDhQqWkpGjy5Mn2DQ0AAKKGraHzv//7vxo3blzw+bx58yRJM2bM0CuvvKInn3xSx48f1z//8z/r6NGjGjt2rIqLi+VyuewaGQAARBGHZVmW3UN0ptraWrndbvn9fs7XAQAgSnTU7++IPUcHAADgYhE6AADAWIQOAAAwFqEDAACMZetVV0C0agxYKq2s0cG6eiXFu5SVniBnjMPusQAA5yB0gDYqLvOpcG25fP764JrX7VJBXoZyM702TgYAOBeHroA2KC7zKX/VjpDIkaQqf73yV+1QcZnPpskAAC0hdIAwNQYsFa4tV0s3nmpaK1xbrsaA0bemAoCoQugAYSqtrGm2J+dsliSfv16llTVdNxQA4LwIHSBMB+taj5z2bAcA6HyEDhCmpPjw/sZauNsBADofoQOEKSs9QV63S61dRO7QmauvstITunIsAMB5EDpAmJwxDhXkZUhSs9hpel6Ql8H9dAAgghA6QBvkZnq1YvoIedyhh6c8bpdWTB/BfXQAIMJww0CgjXIzvZqY4eHOyAAQBQgdoB2cMQ6NGdDb7jEAABfAoSsAAGAsQgcAABiL0AEAAMYidAAAgLEIHQAAYCxCBwAAGIvQAQAAxiJ0AACAsQgdAABgLEIHAAAYi9ABAADGInQAAICxCB0AAGAsQgcAABiL0AEAAMYidAAAgLEIHQAAYCxCBwAAGIvQAQAAxiJ0AACAsQgdAABgLEIHAAAYi9ABAADGInQAAICxCB0AAGAsQgcAABiL0AEAAMYidAAAgLEIHQAAYCxCBwAAGIvQAQAAxiJ0AACAsQgdAABgLEIHAAAYi9ABAADGInQAAICxutk9AKJTY8BSaWWNDtbVKynepaz0BDljHHaPBQBACEIHbVZc5lPh2nL5/PXBNa/bpYK8DOVmem2cDACAUBy6QpsUl/mUv2pHSORIUpW/Xvmrdqi4zGfTZAAANEfoIGyNAUuFa8tltfBa01rh2nI1BlraAgCArkfoIGyllTXN9uSczZLk89ertLKm64YCAOA8CB2E7WBd65HTnu0AAOhshA7ClhTv6tDtAADobIQOwpaVniCv26XWLiJ36MzVV1npCV05FgAArSJ0EDZnjEMFeRmS1Cx2mp4X5GVwPx0AQMQgdNAmuZlerZg+Qh536OEpj9ulFdNHcB8dAEBE4YaBaLPcTK8mZni4MzIAIOIROmgXZ4xDYwb0tnsMAADOi0NXAADAWIQOAAAwFqEDAACMRegAAABjEToAAMBYER06ixcvlsPhCHkMGTLE7rEAAECUiPjLy6+99lp9+OGHwefdukX8yAAAIEJEfDV069ZNHo/H7jEAAEAUiuhDV5K0e/dupaSkqH///rrvvvu0d+/e827f0NCg2trakAcAALg0RXToZGdn65VXXlFxcbFWrFihyspK3Xjjjaqrq2v1a4qKiuR2u4OP1NTULpwYAABEEodlWZbdQ4Tr6NGjSktL07Jly/Twww+3uE1DQ4MaGhqCz2tra5Wamiq/36+ePXt21agAAOAi1NbWyu12X/Tv74g/R+dsvXr10qBBg7Rnz55Wt4mLi1NcXFwXTgUAACJVRB+6OtexY8dUUVEhr9dr9ygAACAKRHTozJ8/X5s2bdJXX32lLVu2aMqUKXI6nZo2bZrdowEAgCgQ0Yeu9u/fr2nTpunw4cNKTEzU2LFjtXXrViUmJto9GgAAiAIRHTpvvvmm3SMAAIAoFtGHrgAAAC4GoQMAAIxF6AAAAGMROgAAwFiEDgAAMBahAwAAjEXoAAAAYxE6AADAWIQOAAAwFqEDAACMRegAAABjEToAAMBYhA4AADAWoQMAAIxF6AAAAGMROgAAwFiEDgAAMBahAwAAjEXoAAAAYxE6AADAWN3sHiAaNQYslVbW6GBdvZLiXcpKT5AzxmH3WAAA4ByEThsVl/lUuLZcPn99cM3rdqkgL0O5mV4bJwMAAOfi0FUbFJf5lL9qR0jkSFKVv175q3aouMxn02QAAKAlhE6YGgOWCteWy2rhtaa1wrXlagy0tAUAALADoROm0sqaZntyzmZJ8vnrVVpZ03VDAQCA8yJ0wnSwrvXIac92AACg8xE6YUqKd3XodgAAoPMROmHKSk+Q1+1SaxeRO3Tm6qus9ISuHAsAAJwHoRMmZ4xDBXkZktQsdpqeF+RlcD8dAAAiCKHTBrmZXq2YPkIed+jhKY/bpRXTR3AfHQAAIgw3DGyj3EyvJmZ4uDMyAABRgNBpB2eMQ2MG9LZ7DAAAcAEcugIAAMYidAAAgLEIHQAAYCxCBwAAGIvQAQAAxiJ0AACAsQgdAABgLEIHAAAYi9ABAADGMv7OyJZlSZJqa2ttngQAAISr6fd20+/x9jI+dOrq6iRJqampNk8CAADaqq6uTm63u91f77AuNpUiXCAQ0IEDBxQfHy+H49L8w5u1tbVKTU3Vvn371LNnT7vHwQXweUUPPqvowWcVXZo+r/Lycg0ePFgxMe0/08b4PToxMTG66qqr7B4jIvTs2ZMf8CjC5xU9+KyiB59VdOnTp89FRY7EycgAAMBghA4AADAWoXMJiIuLU0FBgeLi4uweBWHg84oefFbRg88qunTk52X8ycgAAODSxR4dAABgLEIHAAAYi9ABAADGInQAAICxCJ1LUL9+/eRwOEIezz33nN1jQdLy5cvVr18/uVwuZWdnq7S01O6R0ILFixc3+xkaMmSI3WNB0ubNm5WXl6eUlBQ5HA6tWbMm5HXLsrRo0SJ5vV716NFDEyZM0O7du+0ZFhf8vGbOnNnsZy03N7dN34PQuUT95Cc/kc/nCz5mz55t90iXvLfeekvz5s1TQUGBduzYoeHDhysnJ0cHDx60ezS04Nprrw35Gfr444/tHgmSjh8/ruHDh2v58uUtvr506VK9+OKLWrlypbZt26bLL79cOTk5qq+v7+JJIV3485Kk3NzckJ+1N954o03fw/g/AYGWxcfHy+Px2D0GzrJs2TI98sgjevDBByVJK1eu1Pvvv69f//rXeuqpp2yeDufq1q0bP0MRaNKkSZo0aVKLr1mWpRdeeEFPP/207rzzTknSa6+9puTkZK1Zs0ZTp07tylGh839eTeLi4i7qZ409Opeo5557Tr1799b111+vn//85zp9+rTdI13STp48qe3bt2vChAnBtZiYGE2YMEElJSU2TobW7N69WykpKerfv7/uu+8+7d271+6RcAGVlZWqqqoK+Tlzu93Kzs7m5yyCbdy4UUlJSRo8eLDy8/N1+PDhNn09e3QuQf/2b/+mESNGKCEhQVu2bNGCBQvk8/m0bNkyu0e7ZB06dEiNjY1KTk4OWU9OTtYXX3xh01RoTXZ2tl555RUNHjxYPp9PhYWFuvHGG1VWVqb4+Hi7x0MrqqqqJKnFn7Om1xBZcnNzdddddyk9PV0VFRX60Y9+pEmTJqmkpEROpzOs9yB0DPHUU09pyZIl593mr3/9q4YMGaJ58+YF14YNG6bY2Fj9y7/8i4qKirg9OhCGs3e1Dxs2TNnZ2UpLS9Pvf/97PfzwwzZOBpjl7MOJQ4cO1bBhwzRgwABt3LhR48ePD+s9CB1DPP7445o5c+Z5t+nfv3+L69nZ2Tp9+rS++uorDR48uBOmw4VceeWVcjqdqq6uDlmvrq7mPJAo0KtXLw0aNEh79uyxexScR9PPUnV1tbxeb3C9urpa1113nU1ToS369++vK6+8Unv27CF0LjWJiYlKTExs19fu3LlTMTExSkpK6uCpEK7Y2FiNHDlS69ev1+TJkyVJgUBA69ev16OPPmrvcLigY8eOqaKiQvfff7/do+A80tPT5fF4tH79+mDY1NbWatu2bcrPz7d3OIRl//79Onz4cEioXgihc4kpKSnRtm3bNG7cOMXHx6ukpERz587V9OnT9Q//8A92j3dJmzdvnmbMmKFRo0YpKytLL7zwgo4fPx68CguRY/78+crLy1NaWpoOHDiggoICOZ1OTZs2ze7RLnnHjh0L2bNWWVmpnTt3KiEhQX379tVjjz2mZ555RldffbXS09O1cOFCpaSkBP8PBrrW+T6vhIQEFRYW6vvf/748Ho8qKir05JNPauDAgcrJyQn/m1i4pGzfvt3Kzs623G635XK5rGuuucZ69tlnrfr6ertHg2VZL730ktW3b18rNjbWysrKsrZu3Wr3SGjBD37wA8vr9VqxsbFWnz59rB/84AfWnj177B4LlmV99NFHlqRmjxkzZliWZVmBQMBauHChlZycbMXFxVnjx4+3vvzyS3uHvoSd7/M6ceKEdeutt1qJiYlW9+7drbS0NOuRRx6xqqqq2vQ9HJZlWR2WZgAAABGE++gAAABjEToAAMBYhA4AADAWoQMAAIxF6AAAAGMROgAAwFiEDgAAMBahAwAAjEXoAIgqjY2N+s53vqO77rorZN3v9ys1NVU//vGPbZoMQCTizsgAos7f/vY3XXfddfrVr36l++67T5L0wAMPaNeuXfrkk08UGxtr84QAIgWhAyAqvfjii1q8eLE+//xzlZaW6p577tEnn3yi4cOH2z0agAhC6ACISpZl6bvf/a6cTqc+++wzzZ49W08//bTdYwGIMIQOgKj1xRdf6JprrtHQoUO1Y8cOdevWze6RAEQYTkYGELV+/etf67LLLlNlZaX2799v9zgAIhB7dABEpS1btujmm2/WBx98oGeeeUaS9OGHH8rhcNg8GYBIwh4dAFHnxIkTmjlzpvLz8zVu3Dj913/9l0pLS7Vy5Uq7RwMQYdijAyDqzJkzR3/84x+1a9cuXXbZZZKkl19+WfPnz9dnn32mfv362TsggIhB6ACIKps2bdL48eO1ceNGjR07NuS1nJwcnT59mkNYAIIIHQAAYCzO0QEAAMYidAAAgLEIHQAAYCxCBwAAGIvQAQAAxiJ0AACAsQgdAABgLEIHAAAYi9ABAADGInQAAICxCB0AAGAsQgcAABjr/wAxEh04TICkfwAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y == X + 10"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PHNfNin2RDxT",
        "outputId": "7c3c0c7b-38a1-4940-c94a-a479d9c82201"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ True,  True,  True,  True,  True,  True,  True,  True])"
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Input and Output Shapes"
      ],
      "metadata": {
        "id": "yBsDYuEBRQxn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a demo tensor for our housing price prediction problem\n",
        "house_info = tf.constant([\"bedroom\", \"bathroom\", \"garage\"])\n",
        "house_price = tf.constant([939700])\n",
        "house_info, house_price"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ca2ds3MKRUcF",
        "outputId": "d69c917c-9399-4458-b3bc-b3e65f0bdf4f"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(<tf.Tensor: shape=(3,), dtype=string, numpy=array([b'bedroom', b'bathroom', b'garage'], dtype=object)>,\n",
              " <tf.Tensor: shape=(1,), dtype=int32, numpy=array([939700], dtype=int32)>)"
            ]
          },
          "metadata": {},
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "house_info.shape, house_price.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OlaR5B9rRyRk",
        "outputId": "9b32731f-2dab-4693-95bd-fdacece02395"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(TensorShape([3]), TensorShape([1]))"
            ]
          },
          "metadata": {},
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X[0], y[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dBjHiF1BR9bt",
        "outputId": "c83f85fb-a177-471d-da1e-4dda638bcd5f"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(-7.0, 3.0)"
            ]
          },
          "metadata": {},
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X[1], y[1]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GMXSBjbPSART",
        "outputId": "47e05362-b25f-4939-f7e1-7edec84ecb34"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(-4.0, 6.0)"
            ]
          },
          "metadata": {},
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "input_shape = X.shape\n",
        "output_shape = y.shape\n",
        "input_shape, output_shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JepjW6ISRz6w",
        "outputId": "b4b2c700-0fec-44a9-e6fd-4aa1ee565b59"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((8,), (8,))"
            ]
          },
          "metadata": {},
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Turn our Numpy Arrays into tensors\n",
        "\n",
        "X = tf.constant(X)\n",
        "y = tf.constant(y)\n",
        "X, y"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZHHc-sE9STjy",
        "outputId": "a2f97dc2-389f-47b1-a528-d5b35e7c6fd5"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(<tf.Tensor: shape=(8,), dtype=float64, numpy=array([-7., -4., -1.,  2.,  5.,  8., 11., 14.])>,\n",
              " <tf.Tensor: shape=(8,), dtype=float64, numpy=array([ 3.,  6.,  9., 12., 15., 18., 21., 24.])>)"
            ]
          },
          "metadata": {},
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "input_shape = X[0].shape\n",
        "output_shape = y[0].shape\n",
        "input_shape, output_shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OZqj0wXDSYpO",
        "outputId": "69008896-11ef-4fe5-ff03-e2469ac4178c"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(TensorShape([]), TensorShape([]))"
            ]
          },
          "metadata": {},
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Steps in modelling with TensorFlow\n",
        "\n",
        "1. **Creating a model** - define the input and output layers, as well as the hidden layers of a deep learning model.\n",
        "2. **Compiling the model** - define the loss function (in other words, the function which tells our model how wrong it is) and the optimizer (tells our model how to improve the patterns its learning) and evaluation metrics (what we can use to interpret the performance of our model).\n",
        "3. **Fitting the model** - Letting the model try to find patterns between X & y (features and labels)\n",
        "4. **Evaluate the model**\n",
        "5. **use the model to predict**"
      ],
      "metadata": {
        "id": "jtpruNacTJbd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Set random seed\n",
        "tf.random.set_seed(42)\n",
        "\n",
        "# 1. Create a model using the Sequential AP\n",
        "model = tf.keras.Sequential()\n",
        "model.add(tf.keras.layers.Dense(1))\n",
        "\n",
        "#  2. Compile the model\n",
        "model.compile(loss=tf.keras.losses.mae,\n",
        "             optimizer=tf.keras.optimizers.SGD(),\n",
        "             metrics=[\"mae\"])\n",
        "\n",
        "# 3. Fit the model\n",
        "model.fit(tf.expand_dims(X, axis=-1), y, epochs=5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pyxNcsnTTK-X",
        "outputId": "7f43f6aa-b06a-49c1-a42a-daf0eff38c73"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 459ms/step - loss: 11.1775 - mae: 11.1775\n",
            "Epoch 2/5\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - loss: 11.0450 - mae: 11.0450\n",
            "Epoch 3/5\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - loss: 10.9125 - mae: 10.9125\n",
            "Epoch 4/5\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - loss: 10.7800 - mae: 10.7800\n",
            "Epoch 5/5\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - loss: 10.6475 - mae: 10.6475\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x79e0b494b5e0>"
            ]
          },
          "metadata": {},
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        },
        "id": "WXi6yJlIUdQH",
        "outputId": "ca18321f-d480-4907-bc41-11f78cc5b305"
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential_9\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_9\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ dense_11 (\u001b[38;5;33mDense\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)                   │               \u001b[38;5;34m2\u001b[0m │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ dense_11 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)                   │               <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span> │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m4\u001b[0m (20.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">4</span> (20.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m2\u001b[0m (8.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2</span> (8.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Optimizer params: \u001b[0m\u001b[38;5;34m2\u001b[0m (12.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Optimizer params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2</span> (12.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X, y"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Cmqk6kvrVb9q",
        "outputId": "371dacc4-98a5-4eea-f134-cc2baeee1280"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(<tf.Tensor: shape=(8,), dtype=float64, numpy=array([-7., -4., -1.,  2.,  5.,  8., 11., 14.])>,\n",
              " <tf.Tensor: shape=(8,), dtype=float64, numpy=array([ 3.,  6.,  9., 12., 15., 18., 21., 24.])>)"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.predict(np.array([17.0]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3MsXbTQ8UhhR",
        "outputId": "f6473e93-d135-4c53-b8bd-9807cb1bb8c1"
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 145ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[14.305548]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = model.predict(np.array([17.0]))\n",
        "y_pred"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PzZ3Sdt-XE9e",
        "outputId": "1c1f602f-8cfc-4d49-f5eb-88f77b1f7f1a"
      },
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[14.305548]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred + 10.64"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BnRRD9oLXJF1",
        "outputId": "5f6499a6-2ee5-4692-a0f0-afe6ca172688"
      },
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[24.945549]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# How to improve our model\n",
        "We can improve our model, by altering the steps we took to create a model.\n",
        "\n",
        "1. **Creating a model** - We might add more layers, increase the number of hidden units (all called neurons) within each of the hidden layers, change the activation function of each layer.\n",
        "2. **Compiling a model** - here we might change the optimization function or perhaps the **learning rate** of the optimization function.\n",
        "3. **Fitting a model** - here we might fit for more epochs (leave it training for longer) or on more data (give the model more examples to learn from)."
      ],
      "metadata": {
        "id": "hlk1_LpiXSqP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Let's rebuild our model to improve increasing the epochs\n",
        "\n",
        "# 1. Create the model\n",
        "model = tf.keras.Sequential([tf.keras.layers.Dense(1)])\n",
        "\n",
        "# 2. Compile the model\n",
        "model.compile(loss=tf.keras.losses.mae,\n",
        "             optimizer=tf.keras.optimizers.SGD(),\n",
        "             metrics=[\"mae\"])\n",
        "\n",
        "# 3. Fit the model\n",
        "model.fit(tf.expand_dims(X, axis=-1), y, epochs=100)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AUn53owgZa6z",
        "outputId": "1ed68a99-bb80-462a-bead-4a76126b5c6f"
      },
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 442ms/step - loss: 18.2049 - mae: 18.2049\n",
            "Epoch 2/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 17.9236 - mae: 17.9236\n",
            "Epoch 3/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 17.6424 - mae: 17.6424\n",
            "Epoch 4/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - loss: 17.3611 - mae: 17.3611\n",
            "Epoch 5/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - loss: 17.0799 - mae: 17.0799\n",
            "Epoch 6/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - loss: 16.7986 - mae: 16.7986\n",
            "Epoch 7/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - loss: 16.5174 - mae: 16.5174\n",
            "Epoch 8/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 16.2361 - mae: 16.2361\n",
            "Epoch 9/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - loss: 15.9549 - mae: 15.9549\n",
            "Epoch 10/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - loss: 15.6736 - mae: 15.6736\n",
            "Epoch 11/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 15.3924 - mae: 15.3924\n",
            "Epoch 12/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 15.1111 - mae: 15.1111\n",
            "Epoch 13/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - loss: 14.8416 - mae: 14.8416\n",
            "Epoch 14/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - loss: 14.7091 - mae: 14.7091\n",
            "Epoch 15/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - loss: 14.5766 - mae: 14.5766\n",
            "Epoch 16/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 14.4441 - mae: 14.4441\n",
            "Epoch 17/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 14.3116 - mae: 14.3116\n",
            "Epoch 18/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - loss: 14.1791 - mae: 14.1791\n",
            "Epoch 19/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - loss: 14.0466 - mae: 14.0466\n",
            "Epoch 20/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 13.9141 - mae: 13.9141\n",
            "Epoch 21/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 13.7816 - mae: 13.7816\n",
            "Epoch 22/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - loss: 13.6491 - mae: 13.6491\n",
            "Epoch 23/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 13.5166 - mae: 13.5166\n",
            "Epoch 24/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - loss: 13.3841 - mae: 13.3841\n",
            "Epoch 25/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - loss: 13.2516 - mae: 13.2516\n",
            "Epoch 26/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - loss: 13.1191 - mae: 13.1191\n",
            "Epoch 27/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - loss: 12.9866 - mae: 12.9866\n",
            "Epoch 28/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - loss: 12.8541 - mae: 12.8541\n",
            "Epoch 29/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - loss: 12.7216 - mae: 12.7216\n",
            "Epoch 30/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - loss: 12.5891 - mae: 12.5891\n",
            "Epoch 31/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - loss: 12.4566 - mae: 12.4566\n",
            "Epoch 32/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - loss: 12.3241 - mae: 12.3241\n",
            "Epoch 33/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - loss: 12.1916 - mae: 12.1916\n",
            "Epoch 34/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - loss: 12.0591 - mae: 12.0591\n",
            "Epoch 35/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - loss: 11.9266 - mae: 11.9266\n",
            "Epoch 36/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - loss: 11.7941 - mae: 11.7941\n",
            "Epoch 37/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 11.6616 - mae: 11.6616\n",
            "Epoch 38/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 11.5291 - mae: 11.5291\n",
            "Epoch 39/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 11.3966 - mae: 11.3966\n",
            "Epoch 40/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 11.2641 - mae: 11.2641\n",
            "Epoch 41/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - loss: 11.1316 - mae: 11.1316\n",
            "Epoch 42/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 10.9991 - mae: 10.9991\n",
            "Epoch 43/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - loss: 10.8666 - mae: 10.8666\n",
            "Epoch 44/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - loss: 10.7341 - mae: 10.7341\n",
            "Epoch 45/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - loss: 10.6016 - mae: 10.6016\n",
            "Epoch 46/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - loss: 10.4691 - mae: 10.4691\n",
            "Epoch 47/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - loss: 10.3366 - mae: 10.3366\n",
            "Epoch 48/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - loss: 10.2041 - mae: 10.2041\n",
            "Epoch 49/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - loss: 10.0716 - mae: 10.0716\n",
            "Epoch 50/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - loss: 9.9391 - mae: 9.9391\n",
            "Epoch 51/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 9.8066 - mae: 9.8066\n",
            "Epoch 52/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 9.6741 - mae: 9.6741\n",
            "Epoch 53/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - loss: 9.5416 - mae: 9.5416\n",
            "Epoch 54/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 9.4091 - mae: 9.4091\n",
            "Epoch 55/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 9.2766 - mae: 9.2766\n",
            "Epoch 56/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 9.1441 - mae: 9.1441\n",
            "Epoch 57/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 9.0116 - mae: 9.0116\n",
            "Epoch 58/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - loss: 8.8791 - mae: 8.8791\n",
            "Epoch 59/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - loss: 8.7466 - mae: 8.7466\n",
            "Epoch 60/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - loss: 8.6141 - mae: 8.6141\n",
            "Epoch 61/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 8.4816 - mae: 8.4816\n",
            "Epoch 62/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 8.3491 - mae: 8.3491\n",
            "Epoch 63/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 8.2166 - mae: 8.2166\n",
            "Epoch 64/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 8.0841 - mae: 8.0841\n",
            "Epoch 65/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 7.9516 - mae: 7.9516\n",
            "Epoch 66/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 7.8191 - mae: 7.8191\n",
            "Epoch 67/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 7.6866 - mae: 7.6866\n",
            "Epoch 68/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - loss: 7.5541 - mae: 7.5541\n",
            "Epoch 69/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - loss: 7.4216 - mae: 7.4216\n",
            "Epoch 70/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - loss: 7.2891 - mae: 7.2891\n",
            "Epoch 71/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 131ms/step - loss: 7.1566 - mae: 7.1566\n",
            "Epoch 72/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - loss: 7.0241 - mae: 7.0241\n",
            "Epoch 73/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 127ms/step - loss: 6.9825 - mae: 6.9825\n",
            "Epoch 74/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - loss: 6.9769 - mae: 6.9769\n",
            "Epoch 75/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - loss: 6.9713 - mae: 6.9713\n",
            "Epoch 76/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - loss: 6.9656 - mae: 6.9656\n",
            "Epoch 77/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - loss: 6.9600 - mae: 6.9600\n",
            "Epoch 78/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - loss: 6.9544 - mae: 6.9544\n",
            "Epoch 79/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - loss: 6.9488 - mae: 6.9488\n",
            "Epoch 80/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - loss: 6.9431 - mae: 6.9431\n",
            "Epoch 81/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - loss: 6.9375 - mae: 6.9375\n",
            "Epoch 82/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - loss: 6.9319 - mae: 6.9319\n",
            "Epoch 83/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - loss: 6.9263 - mae: 6.9263\n",
            "Epoch 84/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 118ms/step - loss: 6.9206 - mae: 6.9206\n",
            "Epoch 85/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 130ms/step - loss: 6.9150 - mae: 6.9150\n",
            "Epoch 86/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - loss: 6.9094 - mae: 6.9094\n",
            "Epoch 87/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - loss: 6.9038 - mae: 6.9038\n",
            "Epoch 88/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - loss: 6.8981 - mae: 6.8981\n",
            "Epoch 89/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - loss: 6.8925 - mae: 6.8925\n",
            "Epoch 90/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - loss: 6.8869 - mae: 6.8869\n",
            "Epoch 91/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - loss: 6.8813 - mae: 6.8813\n",
            "Epoch 92/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - loss: 6.8756 - mae: 6.8756\n",
            "Epoch 93/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - loss: 6.8700 - mae: 6.8700\n",
            "Epoch 94/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - loss: 6.8644 - mae: 6.8644\n",
            "Epoch 95/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - loss: 6.8588 - mae: 6.8588\n",
            "Epoch 96/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - loss: 6.8531 - mae: 6.8531\n",
            "Epoch 97/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - loss: 6.8475 - mae: 6.8475\n",
            "Epoch 98/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - loss: 6.8419 - mae: 6.8419\n",
            "Epoch 99/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 135ms/step - loss: 6.8363 - mae: 6.8363\n",
            "Epoch 100/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 131ms/step - loss: 6.8306 - mae: 6.8306\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x79e0b6dda7a0>"
            ]
          },
          "metadata": {},
          "execution_count": 70
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X, y"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gbUPVXH1Zz7y",
        "outputId": "514c58ac-37e0-408f-d851-3b6bab0191b4"
      },
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(<tf.Tensor: shape=(8,), dtype=float64, numpy=array([-7., -4., -1.,  2.,  5.,  8., 11., 14.])>,\n",
              " <tf.Tensor: shape=(8,), dtype=float64, numpy=array([ 3.,  6.,  9., 12., 15., 18., 21., 24.])>)"
            ]
          },
          "metadata": {},
          "execution_count": 63
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = model.predict(np.array([17.0]))\n",
        "y_pred"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FhCKbrpjZ1QU",
        "outputId": "a74f19dc-9bee-446c-bfd7-a3371f1f09a7"
      },
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[29.886839]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 65
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred + 6.9113"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KPekV-CIZ8XG",
        "outputId": "82504682-cc95-47fd-ad07-38e73cf7b7cf"
      },
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[36.798138]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 66
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Remind ourselves of the data\n",
        "X, y"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-8-DWDxlaQqg",
        "outputId": "ee232dd3-bc8a-4b60-f603-4bbb538f4113"
      },
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(<tf.Tensor: shape=(8,), dtype=float64, numpy=array([-7., -4., -1.,  2.,  5.,  8., 11., 14.])>,\n",
              " <tf.Tensor: shape=(8,), dtype=float64, numpy=array([ 3.,  6.,  9., 12., 15., 18., 21., 24.])>)"
            ]
          },
          "metadata": {},
          "execution_count": 67
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.predict(np.array([17.0],dtype=np.float32))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FqDXZKW9aU5S",
        "outputId": "f2f11349-37f7-4fbb-f395-fb76684eead6"
      },
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[29.886839]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 69
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Improving continued by adding a hidden layer"
      ],
      "metadata": {
        "id": "8edswcxqazxQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Improve the model by adding a hidden layer\n",
        "model = tf.keras.Sequential()\n",
        "model.add(tf.keras.layers.Dense(100, activation=\"relu\"))\n",
        "# model.add(tf.keras.layers.Dense(100, activation=\"relu\"))\n",
        "# model.add(tf.keras.layers.Dense(100, activation=\"relu\"))\n",
        "model.add(tf.keras.layers.Dense(1))\n",
        "\n",
        "# Compile the model\n",
        "model.compile(loss=tf.keras.losses.mae,\n",
        "              optimizer=tf.keras.optimizers.SGD(),\n",
        "              metrics=[\"mae\"])\n",
        "\n",
        "# Fit the model\n",
        "model.fit(tf.expand_dims(X, axis=-1), y, epochs=100)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9YFIbiZBXPK9",
        "outputId": "deea2a79-9b28-488b-84be-daf383305f00"
      },
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 751ms/step - loss: 13.4396 - mae: 13.4396\n",
            "Epoch 2/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - loss: 12.9687 - mae: 12.9687\n",
            "Epoch 3/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - loss: 12.5003 - mae: 12.5003\n",
            "Epoch 4/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - loss: 12.0247 - mae: 12.0247\n",
            "Epoch 5/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - loss: 11.5486 - mae: 11.5486\n",
            "Epoch 6/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 11.0700 - mae: 11.0700\n",
            "Epoch 7/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - loss: 10.5938 - mae: 10.5938\n",
            "Epoch 8/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - loss: 10.0907 - mae: 10.0907\n",
            "Epoch 9/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - loss: 9.5616 - mae: 9.5616\n",
            "Epoch 10/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 9.0080 - mae: 9.0080\n",
            "Epoch 11/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 115ms/step - loss: 8.4818 - mae: 8.4818\n",
            "Epoch 12/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - loss: 7.9148 - mae: 7.9148\n",
            "Epoch 13/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - loss: 7.3016 - mae: 7.3016\n",
            "Epoch 14/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - loss: 6.6413 - mae: 6.6413\n",
            "Epoch 15/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 138ms/step - loss: 5.9306 - mae: 5.9306\n",
            "Epoch 16/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - loss: 5.1581 - mae: 5.1581\n",
            "Epoch 17/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 125ms/step - loss: 4.3167 - mae: 4.3167\n",
            "Epoch 18/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 3.9410 - mae: 3.9410\n",
            "Epoch 19/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - loss: 3.9280 - mae: 3.9280\n",
            "Epoch 20/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - loss: 3.9242 - mae: 3.9242\n",
            "Epoch 21/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - loss: 3.9350 - mae: 3.9350\n",
            "Epoch 22/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 3.8989 - mae: 3.8989\n",
            "Epoch 23/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - loss: 3.9411 - mae: 3.9411\n",
            "Epoch 24/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - loss: 3.8766 - mae: 3.8766\n",
            "Epoch 25/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - loss: 3.9433 - mae: 3.9433\n",
            "Epoch 26/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 3.8827 - mae: 3.8827\n",
            "Epoch 27/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - loss: 3.9265 - mae: 3.9265\n",
            "Epoch 28/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - loss: 3.8977 - mae: 3.8977\n",
            "Epoch 29/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - loss: 3.9010 - mae: 3.9010\n",
            "Epoch 30/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - loss: 3.9038 - mae: 3.9038\n",
            "Epoch 31/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 139ms/step - loss: 3.8754 - mae: 3.8754\n",
            "Epoch 32/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 3.9101 - mae: 3.9101\n",
            "Epoch 33/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - loss: 3.8498 - mae: 3.8498\n",
            "Epoch 34/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 3.9167 - mae: 3.9167\n",
            "Epoch 35/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - loss: 3.8602 - mae: 3.8602\n",
            "Epoch 36/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - loss: 3.9023 - mae: 3.9023\n",
            "Epoch 37/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 3.8675 - mae: 3.8675\n",
            "Epoch 38/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - loss: 3.8766 - mae: 3.8766\n",
            "Epoch 39/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - loss: 3.8738 - mae: 3.8738\n",
            "Epoch 40/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 3.8508 - mae: 3.8508\n",
            "Epoch 41/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 127ms/step - loss: 3.8804 - mae: 3.8804\n",
            "Epoch 42/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - loss: 3.8250 - mae: 3.8250\n",
            "Epoch 43/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 133ms/step - loss: 3.8943 - mae: 3.8943\n",
            "Epoch 44/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - loss: 3.8320 - mae: 3.8320\n",
            "Epoch 45/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - loss: 3.8769 - mae: 3.8769\n",
            "Epoch 46/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - loss: 3.8384 - mae: 3.8384\n",
            "Epoch 47/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 137ms/step - loss: 3.8509 - mae: 3.8509\n",
            "Epoch 48/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - loss: 3.8450 - mae: 3.8450\n",
            "Epoch 49/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - loss: 3.8249 - mae: 3.8249\n",
            "Epoch 50/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - loss: 3.8519 - mae: 3.8519\n",
            "Epoch 51/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - loss: 3.8057 - mae: 3.8057\n",
            "Epoch 52/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 3.8676 - mae: 3.8676\n",
            "Epoch 53/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 3.8039 - mae: 3.8039\n",
            "Epoch 54/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - loss: 3.8502 - mae: 3.8502\n",
            "Epoch 55/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - loss: 3.8105 - mae: 3.8105\n",
            "Epoch 56/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - loss: 3.8240 - mae: 3.8240\n",
            "Epoch 57/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - loss: 3.8174 - mae: 3.8174\n",
            "Epoch 58/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - loss: 3.7978 - mae: 3.7978\n",
            "Epoch 59/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - loss: 3.8302 - mae: 3.8302\n",
            "Epoch 60/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - loss: 3.7795 - mae: 3.7795\n",
            "Epoch 61/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - loss: 3.8403 - mae: 3.8403\n",
            "Epoch 62/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - loss: 3.7769 - mae: 3.7769\n",
            "Epoch 63/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - loss: 3.8222 - mae: 3.8222\n",
            "Epoch 64/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - loss: 3.7837 - mae: 3.7837\n",
            "Epoch 65/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - loss: 3.7959 - mae: 3.7959\n",
            "Epoch 66/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 3.7909 - mae: 3.7909\n",
            "Epoch 67/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 3.7744 - mae: 3.7744\n",
            "Epoch 68/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 3.8069 - mae: 3.8069\n",
            "Epoch 69/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 3.7507 - mae: 3.7507\n",
            "Epoch 70/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - loss: 3.8140 - mae: 3.8140\n",
            "Epoch 71/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - loss: 3.7509 - mae: 3.7509\n",
            "Epoch 72/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - loss: 3.7930 - mae: 3.7930\n",
            "Epoch 73/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 3.7581 - mae: 3.7581\n",
            "Epoch 74/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - loss: 3.7664 - mae: 3.7664\n",
            "Epoch 75/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 3.7690 - mae: 3.7690\n",
            "Epoch 76/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - loss: 3.7477 - mae: 3.7477\n",
            "Epoch 77/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - loss: 3.7815 - mae: 3.7815\n",
            "Epoch 78/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - loss: 3.7205 - mae: 3.7205\n",
            "Epoch 79/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - loss: 3.7888 - mae: 3.7888\n",
            "Epoch 80/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - loss: 3.7261 - mae: 3.7261\n",
            "Epoch 81/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - loss: 3.7626 - mae: 3.7626\n",
            "Epoch 82/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 136ms/step - loss: 3.7335 - mae: 3.7335\n",
            "Epoch 83/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 3.7383 - mae: 3.7383\n",
            "Epoch 84/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - loss: 3.7497 - mae: 3.7497\n",
            "Epoch 85/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 3.7165 - mae: 3.7165\n",
            "Epoch 86/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 3.7571 - mae: 3.7571\n",
            "Epoch 87/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - loss: 3.6949 - mae: 3.6949\n",
            "Epoch 88/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - loss: 3.7579 - mae: 3.7579\n",
            "Epoch 89/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - loss: 3.7023 - mae: 3.7023\n",
            "Epoch 90/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 3.7309 - mae: 3.7309\n",
            "Epoch 91/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - loss: 3.7110 - mae: 3.7110\n",
            "Epoch 92/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - loss: 3.7117 - mae: 3.7117\n",
            "Epoch 93/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 134ms/step - loss: 3.7262 - mae: 3.7262\n",
            "Epoch 94/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - loss: 3.6840 - mae: 3.6840\n",
            "Epoch 95/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - loss: 3.7338 - mae: 3.7338\n",
            "Epoch 96/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - loss: 3.6718 - mae: 3.6718\n",
            "Epoch 97/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - loss: 3.7252 - mae: 3.7252\n",
            "Epoch 98/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - loss: 3.6795 - mae: 3.6795\n",
            "Epoch 99/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - loss: 3.6978 - mae: 3.6978\n",
            "Epoch 100/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - loss: 3.6960 - mae: 3.6960\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x79e0b364ea40>"
            ]
          },
          "metadata": {},
          "execution_count": 80
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Let's remind ourselves of the data\n",
        "X,y"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HZWCa3P1dcM4",
        "outputId": "63972816-7991-4248-9b78-768db825f7d5"
      },
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(<tf.Tensor: shape=(8,), dtype=float64, numpy=array([-7., -4., -1.,  2.,  5.,  8., 11., 14.])>,\n",
              " <tf.Tensor: shape=(8,), dtype=float64, numpy=array([ 3.,  6.,  9., 12., 15., 18., 21., 24.])>)"
            ]
          },
          "metadata": {},
          "execution_count": 82
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = model.predict(np.array([17.0]))\n",
        "y_pred"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "piuORs9ydkVL",
        "outputId": "4b8c797e-090b-4dea-b916-e3a2ddffd03c"
      },
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[31.645266]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 83
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Improve the model by adding a hidden layer\n",
        "model = tf.keras.Sequential()\n",
        "model.add(tf.keras.layers.Dense(50, activation=None))\n",
        "# model.add(tf.keras.layers.Dense(100, activation=\"relu\"))\n",
        "# model.add(tf.keras.layers.Dense(100, activation=\"relu\"))\n",
        "model.add(tf.keras.layers.Dense(1))\n",
        "\n",
        "# Compile the model\n",
        "model.compile(loss=tf.keras.losses.mae,\n",
        "              optimizer=tf.keras.optimizers.SGD(),\n",
        "              metrics=[\"mae\"])\n",
        "\n",
        "# Fit the model\n",
        "model.fit(tf.expand_dims(X, axis=-1), y, epochs=100)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4MzdR50eeIgp",
        "outputId": "9f98b18d-5320-43ac-b9d8-65912a3c018c"
      },
      "execution_count": 88,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - loss: 12.4162 - mae: 12.4162\n",
            "Epoch 2/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - loss: 11.9173 - mae: 11.9173\n",
            "Epoch 3/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - loss: 11.4114 - mae: 11.4114\n",
            "Epoch 4/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 10.8958 - mae: 10.8958\n",
            "Epoch 5/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 10.3679 - mae: 10.3679\n",
            "Epoch 6/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - loss: 9.8250 - mae: 9.8250\n",
            "Epoch 7/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 9.2643 - mae: 9.2643\n",
            "Epoch 8/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 8.6830 - mae: 8.6830\n",
            "Epoch 9/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 8.0780 - mae: 8.0780\n",
            "Epoch 10/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 7.4463 - mae: 7.4463\n",
            "Epoch 11/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 7.2488 - mae: 7.2488\n",
            "Epoch 12/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 7.2282 - mae: 7.2282\n",
            "Epoch 13/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - loss: 7.2075 - mae: 7.2075\n",
            "Epoch 14/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - loss: 7.1868 - mae: 7.1868\n",
            "Epoch 15/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - loss: 7.1661 - mae: 7.1661\n",
            "Epoch 16/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - loss: 7.1453 - mae: 7.1453\n",
            "Epoch 17/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - loss: 7.1244 - mae: 7.1244\n",
            "Epoch 18/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - loss: 7.1035 - mae: 7.1035\n",
            "Epoch 19/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - loss: 7.0825 - mae: 7.0825\n",
            "Epoch 20/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - loss: 7.0615 - mae: 7.0615\n",
            "Epoch 21/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - loss: 7.0404 - mae: 7.0404\n",
            "Epoch 22/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 7.0192 - mae: 7.0192\n",
            "Epoch 23/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 6.9979 - mae: 6.9979\n",
            "Epoch 24/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - loss: 6.9766 - mae: 6.9766\n",
            "Epoch 25/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 6.9651 - mae: 6.9651\n",
            "Epoch 26/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 6.9478 - mae: 6.9478\n",
            "Epoch 27/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 6.9268 - mae: 6.9268\n",
            "Epoch 28/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 6.9057 - mae: 6.9057\n",
            "Epoch 29/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 6.8845 - mae: 6.8845\n",
            "Epoch 30/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 6.8633 - mae: 6.8633\n",
            "Epoch 31/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - loss: 6.8419 - mae: 6.8419\n",
            "Epoch 32/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 6.8204 - mae: 6.8204\n",
            "Epoch 33/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 6.7988 - mae: 6.7988\n",
            "Epoch 34/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 6.7771 - mae: 6.7771\n",
            "Epoch 35/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - loss: 6.7552 - mae: 6.7552\n",
            "Epoch 36/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - loss: 6.7333 - mae: 6.7333\n",
            "Epoch 37/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - loss: 6.7112 - mae: 6.7112\n",
            "Epoch 38/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - loss: 6.6890 - mae: 6.6890\n",
            "Epoch 39/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - loss: 6.6667 - mae: 6.6667\n",
            "Epoch 40/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - loss: 6.6443 - mae: 6.6443\n",
            "Epoch 41/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - loss: 6.6217 - mae: 6.6217\n",
            "Epoch 42/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - loss: 6.5989 - mae: 6.5989\n",
            "Epoch 43/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - loss: 6.5760 - mae: 6.5760\n",
            "Epoch 44/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - loss: 6.5530 - mae: 6.5530\n",
            "Epoch 45/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - loss: 6.5298 - mae: 6.5298\n",
            "Epoch 46/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - loss: 6.5065 - mae: 6.5065\n",
            "Epoch 47/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 6.4830 - mae: 6.4830\n",
            "Epoch 48/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 6.4593 - mae: 6.4593\n",
            "Epoch 49/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 6.4467 - mae: 6.4467\n",
            "Epoch 50/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 6.4325 - mae: 6.4325\n",
            "Epoch 51/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 6.4089 - mae: 6.4089\n",
            "Epoch 52/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - loss: 6.3852 - mae: 6.3852\n",
            "Epoch 53/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 6.3612 - mae: 6.3612\n",
            "Epoch 54/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 6.3371 - mae: 6.3371\n",
            "Epoch 55/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 6.3128 - mae: 6.3128\n",
            "Epoch 56/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - loss: 6.2883 - mae: 6.2883\n",
            "Epoch 57/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - loss: 6.2636 - mae: 6.2636\n",
            "Epoch 58/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - loss: 6.2387 - mae: 6.2387\n",
            "Epoch 59/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - loss: 6.2136 - mae: 6.2136\n",
            "Epoch 60/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - loss: 6.1882 - mae: 6.1882\n",
            "Epoch 61/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - loss: 6.1627 - mae: 6.1627\n",
            "Epoch 62/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 6.1370 - mae: 6.1370\n",
            "Epoch 63/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - loss: 6.1110 - mae: 6.1110\n",
            "Epoch 64/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - loss: 6.0848 - mae: 6.0848\n",
            "Epoch 65/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - loss: 6.0583 - mae: 6.0583\n",
            "Epoch 66/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 6.0316 - mae: 6.0316\n",
            "Epoch 67/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 6.0116 - mae: 6.0116\n",
            "Epoch 68/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - loss: 6.0037 - mae: 6.0037\n",
            "Epoch 69/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 5.9768 - mae: 5.9768\n",
            "Epoch 70/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - loss: 5.9498 - mae: 5.9498\n",
            "Epoch 71/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - loss: 5.9225 - mae: 5.9225\n",
            "Epoch 72/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 5.8949 - mae: 5.8949\n",
            "Epoch 73/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - loss: 5.8670 - mae: 5.8670\n",
            "Epoch 74/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 5.8389 - mae: 5.8389\n",
            "Epoch 75/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - loss: 5.8105 - mae: 5.8105\n",
            "Epoch 76/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 5.7819 - mae: 5.7819\n",
            "Epoch 77/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - loss: 5.7529 - mae: 5.7529\n",
            "Epoch 78/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - loss: 5.7237 - mae: 5.7237\n",
            "Epoch 79/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - loss: 5.6941 - mae: 5.6941\n",
            "Epoch 80/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - loss: 5.6643 - mae: 5.6643\n",
            "Epoch 81/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - loss: 5.6341 - mae: 5.6341\n",
            "Epoch 82/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - loss: 5.6036 - mae: 5.6036\n",
            "Epoch 83/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - loss: 5.5906 - mae: 5.5906\n",
            "Epoch 84/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - loss: 5.5723 - mae: 5.5723\n",
            "Epoch 85/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - loss: 5.6971 - mae: 5.6971\n",
            "Epoch 86/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 5.5062 - mae: 5.5062\n",
            "Epoch 87/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 5.4747 - mae: 5.4747\n",
            "Epoch 88/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - loss: 5.4427 - mae: 5.4427\n",
            "Epoch 89/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - loss: 5.4105 - mae: 5.4105\n",
            "Epoch 90/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 5.3779 - mae: 5.3779\n",
            "Epoch 91/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 5.3449 - mae: 5.3449\n",
            "Epoch 92/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - loss: 5.3115 - mae: 5.3115\n",
            "Epoch 93/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 5.2778 - mae: 5.2778\n",
            "Epoch 94/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 5.2644 - mae: 5.2644\n",
            "Epoch 95/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 5.2857 - mae: 5.2857\n",
            "Epoch 96/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - loss: 5.3742 - mae: 5.3742\n",
            "Epoch 97/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - loss: 5.1696 - mae: 5.1696\n",
            "Epoch 98/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - loss: 5.1345 - mae: 5.1345\n",
            "Epoch 99/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - loss: 5.0990 - mae: 5.0990\n",
            "Epoch 100/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - loss: 5.0631 - mae: 5.0631\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x79e0b6c3a9e0>"
            ]
          },
          "metadata": {},
          "execution_count": 88
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = model.predict(np.array([17.0]))\n",
        "y_pred"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "519QK-HxeMQO",
        "outputId": "97009266-56a8-416f-a828-1d40146873bd"
      },
      "execution_count": 89,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:5 out of the last 9 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x79e0b61ad630> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[30.050879]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 89
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Improve the model by adding a hidden layer\n",
        "model = tf.keras.Sequential()\n",
        "model.add(tf.keras.layers.Dense(50, activation=None))\n",
        "# model.add(tf.keras.layers.Dense(100, activation=\"relu\"))\n",
        "# model.add(tf.keras.layers.Dense(100, activation=\"relu\"))\n",
        "model.add(tf.keras.layers.Dense(1))\n",
        "\n",
        "# Compile the model\n",
        "model.compile(loss=tf.keras.losses.mae,\n",
        "              optimizer=tf.keras.optimizers.Adam(learning_rate=0.01),\n",
        "              metrics=[\"mae\"])\n",
        "\n",
        "# Fit the model\n",
        "model.fit(tf.expand_dims(X, axis=-1), y, epochs=100)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pb733tgvemfw",
        "outputId": "b607e277-b3f7-4e3d-a2cf-84287c06dcd5"
      },
      "execution_count": 91,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 986ms/step - loss: 13.1191 - mae: 13.1191\n",
            "Epoch 2/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - loss: 12.4798 - mae: 12.4798\n",
            "Epoch 3/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 11.8466 - mae: 11.8466\n",
            "Epoch 4/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 11.2164 - mae: 11.2164\n",
            "Epoch 5/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 10.5865 - mae: 10.5865\n",
            "Epoch 6/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - loss: 9.9541 - mae: 9.9541\n",
            "Epoch 7/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 9.3163 - mae: 9.3163\n",
            "Epoch 8/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 8.6693 - mae: 8.6693\n",
            "Epoch 9/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 8.0093 - mae: 8.0093\n",
            "Epoch 10/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 7.3322 - mae: 7.3322\n",
            "Epoch 11/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 6.8380 - mae: 6.8380\n",
            "Epoch 12/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - loss: 6.8877 - mae: 6.8877\n",
            "Epoch 13/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - loss: 7.1493 - mae: 7.1493\n",
            "Epoch 14/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - loss: 7.3085 - mae: 7.3085\n",
            "Epoch 15/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - loss: 7.3951 - mae: 7.3951\n",
            "Epoch 16/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - loss: 7.3616 - mae: 7.3616\n",
            "Epoch 17/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - loss: 7.1980 - mae: 7.1980\n",
            "Epoch 18/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - loss: 7.0279 - mae: 7.0279\n",
            "Epoch 19/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - loss: 6.8289 - mae: 6.8289\n",
            "Epoch 20/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 6.6072 - mae: 6.6072\n",
            "Epoch 21/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - loss: 6.3684 - mae: 6.3684\n",
            "Epoch 22/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - loss: 6.2245 - mae: 6.2245\n",
            "Epoch 23/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - loss: 6.1846 - mae: 6.1846\n",
            "Epoch 24/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 6.1546 - mae: 6.1546\n",
            "Epoch 25/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 6.1960 - mae: 6.1960\n",
            "Epoch 26/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 6.1374 - mae: 6.1374\n",
            "Epoch 27/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 5.9915 - mae: 5.9915\n",
            "Epoch 28/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - loss: 5.8414 - mae: 5.8414\n",
            "Epoch 29/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 5.7474 - mae: 5.7474\n",
            "Epoch 30/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 5.6503 - mae: 5.6503\n",
            "Epoch 31/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 5.5501 - mae: 5.5501\n",
            "Epoch 32/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 5.5273 - mae: 5.5273\n",
            "Epoch 33/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - loss: 5.4911 - mae: 5.4911\n",
            "Epoch 34/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 5.4153 - mae: 5.4153\n",
            "Epoch 35/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - loss: 5.3033 - mae: 5.3033\n",
            "Epoch 36/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - loss: 5.1584 - mae: 5.1584\n",
            "Epoch 37/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - loss: 5.0036 - mae: 5.0036\n",
            "Epoch 38/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - loss: 4.9165 - mae: 4.9165\n",
            "Epoch 39/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - loss: 4.8219 - mae: 4.8219\n",
            "Epoch 40/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - loss: 4.7200 - mae: 4.7200\n",
            "Epoch 41/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - loss: 4.6104 - mae: 4.6104\n",
            "Epoch 42/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - loss: 4.4931 - mae: 4.4931\n",
            "Epoch 43/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 4.3679 - mae: 4.3679\n",
            "Epoch 44/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - loss: 4.2346 - mae: 4.2346\n",
            "Epoch 45/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 4.0930 - mae: 4.0930\n",
            "Epoch 46/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 3.9429 - mae: 3.9429\n",
            "Epoch 47/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 3.7840 - mae: 3.7840\n",
            "Epoch 48/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - loss: 3.6160 - mae: 3.6160\n",
            "Epoch 49/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - loss: 3.4388 - mae: 3.4388\n",
            "Epoch 50/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 3.2520 - mae: 3.2520\n",
            "Epoch 51/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 3.0986 - mae: 3.0986\n",
            "Epoch 52/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 2.9025 - mae: 2.9025\n",
            "Epoch 53/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - loss: 2.6716 - mae: 2.6716\n",
            "Epoch 54/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - loss: 2.4684 - mae: 2.4684\n",
            "Epoch 55/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - loss: 2.2526 - mae: 2.2526\n",
            "Epoch 56/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - loss: 2.0240 - mae: 2.0240\n",
            "Epoch 57/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - loss: 1.8160 - mae: 1.8160\n",
            "Epoch 58/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - loss: 1.5148 - mae: 1.5148\n",
            "Epoch 59/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - loss: 1.3430 - mae: 1.3430\n",
            "Epoch 60/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - loss: 1.1199 - mae: 1.1199\n",
            "Epoch 61/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - loss: 0.7257 - mae: 0.7257\n",
            "Epoch 62/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - loss: 0.5965 - mae: 0.5965\n",
            "Epoch 63/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - loss: 0.4126 - mae: 0.4126\n",
            "Epoch 64/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.1619 - mae: 0.1619\n",
            "Epoch 65/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.5630 - mae: 0.5630\n",
            "Epoch 66/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 0.6967 - mae: 0.6967\n",
            "Epoch 67/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.5955 - mae: 0.5955\n",
            "Epoch 68/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.7256 - mae: 0.7256\n",
            "Epoch 69/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.6834 - mae: 0.6834\n",
            "Epoch 70/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - loss: 0.5804 - mae: 0.5804\n",
            "Epoch 71/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.5775 - mae: 0.5775\n",
            "Epoch 72/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 0.3972 - mae: 0.3972\n",
            "Epoch 73/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.3221 - mae: 0.3221\n",
            "Epoch 74/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - loss: 0.1177 - mae: 0.1177\n",
            "Epoch 75/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - loss: 0.1273 - mae: 0.1273\n",
            "Epoch 76/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - loss: 0.2734 - mae: 0.2734\n",
            "Epoch 77/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - loss: 0.3478 - mae: 0.3478\n",
            "Epoch 78/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - loss: 0.3048 - mae: 0.3048\n",
            "Epoch 79/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - loss: 0.3502 - mae: 0.3502\n",
            "Epoch 80/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - loss: 0.2751 - mae: 0.2751\n",
            "Epoch 81/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - loss: 0.2238 - mae: 0.2238\n",
            "Epoch 82/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - loss: 0.1435 - mae: 0.1435\n",
            "Epoch 83/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.1674 - mae: 0.1674\n",
            "Epoch 84/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.0903 - mae: 0.0903\n",
            "Epoch 85/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.1390 - mae: 0.1390\n",
            "Epoch 86/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - loss: 0.2447 - mae: 0.2447\n",
            "Epoch 87/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - loss: 0.1651 - mae: 0.1651\n",
            "Epoch 88/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.2007 - mae: 0.2007\n",
            "Epoch 89/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - loss: 0.0733 - mae: 0.0733\n",
            "Epoch 90/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - loss: 0.1417 - mae: 0.1417\n",
            "Epoch 91/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.1157 - mae: 0.1157\n",
            "Epoch 92/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.1334 - mae: 0.1334\n",
            "Epoch 93/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - loss: 0.2123 - mae: 0.2123\n",
            "Epoch 94/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.1424 - mae: 0.1424\n",
            "Epoch 95/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.2467 - mae: 0.2467\n",
            "Epoch 96/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - loss: 0.1539 - mae: 0.1539\n",
            "Epoch 97/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.2402 - mae: 0.2402\n",
            "Epoch 98/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - loss: 0.2832 - mae: 0.2832\n",
            "Epoch 99/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - loss: 0.1160 - mae: 0.1160\n",
            "Epoch 100/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - loss: 0.2198 - mae: 0.2198\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x79e0b5dd5cf0>"
            ]
          },
          "metadata": {},
          "execution_count": 91
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = model.predict(np.array([17.0]))\n",
        "y_pred"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oVKlO-gJe4NY",
        "outputId": "ef6effcc-c765-4078-ed66-5444b9ce8ed2"
      },
      "execution_count": 92,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:6 out of the last 10 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x79e0b5e31360> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[27.412004]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 92
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Evaluation a model\n",
        "\n",
        "In practise, a typical workflow you'll go through when building neural networks is:\n",
        "\n",
        "```\n",
        "Build a model -> fit it -> evaluate it -> tweak a model -> fit it -> evaluate it -> tweak a model -> fit it -> evaluate it -> tweak a model\n",
        "```"
      ],
      "metadata": {
        "id": "6bcaAHBVfK1w"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "When it comes to evaluation... there are three words you should memorize:\n",
        "\n",
        "  - \"Visualize, Visualize, visualize\"\n",
        "\n",
        "Its a good idea to visualize:\n",
        "* The data - what data are we working with? What does it look like?\n",
        "* The model itself - what does our model look like?\n",
        "* The training of a model - how does a model perform while it learns?\n",
        "* The prediction of the model - how do the prediction of a model line up against the ground truth (the original value)"
      ],
      "metadata": {
        "id": "JmEKMKD8f9Up"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Make a bigger dataset\n",
        "X = tf.range(-100, 100, 4)\n",
        "X"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OTQ201qsfosa",
        "outputId": "7a91efcc-a2b4-43a2-c88a-fb47c032ff7c"
      },
      "execution_count": 93,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(50,), dtype=int32, numpy=\n",
              "array([-100,  -96,  -92,  -88,  -84,  -80,  -76,  -72,  -68,  -64,  -60,\n",
              "        -56,  -52,  -48,  -44,  -40,  -36,  -32,  -28,  -24,  -20,  -16,\n",
              "        -12,   -8,   -4,    0,    4,    8,   12,   16,   20,   24,   28,\n",
              "         32,   36,   40,   44,   48,   52,   56,   60,   64,   68,   72,\n",
              "         76,   80,   84,   88,   92,   96], dtype=int32)>"
            ]
          },
          "metadata": {},
          "execution_count": 93
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Make labels for the dataset\n",
        "y = X + 10\n",
        "y"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nsW4CEbrgceU",
        "outputId": "26c99e8c-7808-4749-aea0-ef2e46fccf89"
      },
      "execution_count": 94,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(50,), dtype=int32, numpy=\n",
              "array([-90, -86, -82, -78, -74, -70, -66, -62, -58, -54, -50, -46, -42,\n",
              "       -38, -34, -30, -26, -22, -18, -14, -10,  -6,  -2,   2,   6,  10,\n",
              "        14,  18,  22,  26,  30,  34,  38,  42,  46,  50,  54,  58,  62,\n",
              "        66,  70,  74,  78,  82,  86,  90,  94,  98, 102, 106], dtype=int32)>"
            ]
          },
          "metadata": {},
          "execution_count": 94
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualize the data\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.scatter(X,y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 447
        },
        "id": "CIsROuEagkc9",
        "outputId": "4b3b8e5e-aa65-4903-bf57-cb94cf58f50b"
      },
      "execution_count": 96,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.collections.PathCollection at 0x79e0b6702f20>"
            ]
          },
          "metadata": {},
          "execution_count": 96
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### The 3 sets...\n",
        "* **Training set** - The model learns from this data, which is typically 70-80% of the total data you have available.\n",
        "* **Validation set** - the model gets tuned on this data, which is typically 10-15% of the data available.\n",
        "* **Test set** - the model gets evaluated on this data to test what it has learned, this set is typically 10-15% of the data available"
      ],
      "metadata": {
        "id": "CoYg8JJrhHPC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Check the length of how many samples we have\n",
        "len(X)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NPSgD8G6gweS",
        "outputId": "5f92c5c2-9114-447f-8918-56162ce31235"
      },
      "execution_count": 97,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "50"
            ]
          },
          "metadata": {},
          "execution_count": 97
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Split the data into train and test sets\n",
        "X_train = X[:40]\n",
        "y_train = y[:40]\n",
        "\n",
        "X_test = X[40:]\n",
        "y_test = y[40:]\n",
        "\n",
        "len(X_train), len(X_test)"
      ],
      "metadata": {
        "id": "s-hEp5n-iHL8"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}